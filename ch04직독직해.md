## 4.1 AML의 주요 도전 과제

### 4.1.1 신뢰 가능한 AI 속성 간의 트레이드오프

- AI의 신뢰성은 정확도, 강건성, 공정성, 설명 가능성 등 여러 속성에 기반함.
- 하나의 속성을 최적화하면 다른 속성이 저하되는 트레이드오프가 발생함.
    - 예: 정확도 ↑ → 강건성/공정성 ↓
    - 예: 강건성 ↑ → 정확도/공정성 ↓
- 다목적 최적화와 파레토 최적성 개념이 이러한 균형 문제를 해결하는 데 유용함.
- 조직은 용도 및 우선순위에 따라 속성 간의 균형을 선택해야 함.

---

### 4.1.2 적대적 강건성에 대한 이론적 한계

- AML 방어 기법은 공격을 탐지하고 방어할 수 있어야 하나, 이론적으로 매우 어려움.
    - Tramèr는 "적대적 예제 탐지는 강건한 분류 문제와 동일"하다고 설명.
- Out-of-Distribution(OOD) 입력 탐지 또한 주요 과제.
- 형식 기법(Formal Methods)은 높은 보안성을 제공하지만,
    - 확장성, 연산 제한, 비용 문제로 인해 대규모 ML 모델 적용이 제한적임.
- 연구는 신경망 구조의 복잡성 증가, 알고리즘 수학 연산, 빠른 코드 변경 대응 등을 고려해 확장되어야 함.

---

### 4.1.3 평가 문제

- 공통된 벤치마크 부재로 인해 AML 연구 간 비교가 어렵고 불일치 발생.
- 새로운 방어 기법은 제안자 스스로 공격해보는 적응형 평가(adversarial testing)가 필요함.
    - 많은 경우 평가가 느슨하여 실제보다 강력해 보이지만, 곧 깨지는 경우 많음.
- 여러 신뢰 속성을 동시에 평가해야 하며, 파레토 플롯을 활용해 트레이드오프 분석 필요.
    - 하나의 속성만 우수한 기법은 절대적인 개선이라 보기 어려움.
    
---

### 4.2.1 데이터 규모의 도전 (The Scale Challenge)

- GenAI 모델은 대규모 데이터셋에 의존함
- 대부분의 모델 개발자는 데이터 출처를 공개하지 않음
- 데이터 저장소는 외부 링크와 라벨 모음으로 구성됨
- 기존 보안 경계를 무력화하는 새로운 위험 요소 발생
- 오픈소스 데이터 중독 도구의 공개로 이미지 데이터 공격 위험 증가

**대응 방안**

- 데이터 및 모델 정화 기법과 암호 기술 결합 가능
- 이론적으로 보증된 강건 학습 기법 개발 필요
- 대형 언어 모델과 생성 확산 모델에 적용 가능한 확장 연구 필요

---

### 4.2.2 공급망의 도전 (Supply Chain Challenges)

- 탐지 어려운 새로운 유형의 AML 공격이 등장함
- 모델 중독은 안전 학습 이후에도 작동 가능함
- 오픈소스 종속성은 감시와 취약점 식별을 어렵게 만듦
- AI 시스템에 대한 과도한 신뢰는 보안 위험을 증가시킴
- 탐지 불가능한 트로이 목마 공격이 연구됨

**대응 방안**

- TrojAI 프로젝트에서 탐지 및 조사 기술 연구 중
- 내부자 위협 방지를 위한 공급망 보안 중요

---

### 4.2.3 멀티모달 모델 (Multimodal Models)

- 멀티모달 모델은 다양한 작업에서 높은 성능을 보임
- 단일 모달리티 공격만으로 전체 모델 손상 가능
- 정보 중복만으로는 강건성 향상 불충분
- 적대적 학습은 모달리티 수 증가 시 계산 비용 급증
- 다중 모달리티 동시 공격도 설계 가능

**시사점**

- 단일 모달리티 기준의 방어 기법은 효과가 제한적일 수 있음

---

### 4.2.4 양자화된 모델 (Quantized Models)

- 양자화는 엣지 디바이스에서 모델 실행을 효율화함
- 저정밀도 표현은 오류 증폭을 초래함
- PredAI 대상 방어 기법은 일부 존재하나 GenAI 대상 연구는 부족
- 악성 양자화 모델은 정상처럼 위장 가능

**시사점**

- 양자화 모델 배포 시 지속적인 동작 모니터링 필요

---

### 4.2.5 AML에 따른 위험 관리 (Risk Management in Light of AML)

- AML 방어의 한계로 인해 전략적 판단이 중요함
- 생성형 AI는 사전 배포 테스트에 적대적 리스크 평가를 도입 중
- NIST는 관련 지침과 위험 프로파일을 발표함
- 이론적 한계:
    - 모든 부적절한 출력을 방지할 수 없음
    - 특정 프롬프트로 원치 않는 동작 유도 가능

**시사점**

- 사전 테스트는 유용하나 충분하지 않음
- 고위험 상황에서는 추가적 조치가 요구됨

---

### 4.2.6 AML과 AI 시스템 특성의 연계 (AML and Other AI System Characteristics)

- AML 대응은 사이버보안 실천과 결합되어야 함
- AML과 기존 보안 체계를 연결하는 방식 필요
- AML은 독립된 영역이며 완전한 해법이나 하위 개념이 아님
- AI 안전성과 신뢰성 확보와의 관계 명확화가 필요함

**시사점**

- AML 대응을 신뢰 가능한 AI 설계와 통합하는 방향으로 연구 지속 필요

